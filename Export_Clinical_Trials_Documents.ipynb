{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "from typing import List\n",
    "from sqlalchemy import create_engine, text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = os.environ[\"USERNAME\"]\n",
    "password = os.environ[\"PASSWORD\"]\n",
    "hostname = os.environ[\"HOSTNAME\"]\n",
    "database = os.environ[\"DATABASE\"]\n",
    "port = os.environ[\"PORT\"]\n",
    "\n",
    "db_credentials = f\"postgresql://{username}:{password}@{hostname}:{port}/{database}\"\n",
    "engine = create_engine(db_credentials)\n",
    "db_connections = engine.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_id</th>\n",
       "      <th>has_protocol</th>\n",
       "      <th>has_icf</th>\n",
       "      <th>has_sap</th>\n",
       "      <th>document_date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00000125</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2019-02-06</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/25/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00001259</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/59/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00001277</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-12-17</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/77/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00001305</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/05/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT00001305</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-04-18</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/05/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40269</th>\n",
       "      <td>NCT05806606</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/06/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40270</th>\n",
       "      <td>NCT05806853</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2019-10-31</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/53/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40271</th>\n",
       "      <td>NCT05806866</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-15</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/66/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40272</th>\n",
       "      <td>NCT05808400</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2023-02-14</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/00/NCT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40273</th>\n",
       "      <td>NCT05808413</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-02-28</td>\n",
       "      <td>https://ClinicalTrials.gov/ProvidedDocs/13/NCT...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40274 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            nct_id  has_protocol  has_icf  has_sap document_date  \\\n",
       "0      NCT00000125         False     True    False    2019-02-06   \n",
       "1      NCT00001259          True    False     True    2019-06-18   \n",
       "2      NCT00001277          True    False     True    2020-12-17   \n",
       "3      NCT00001305          True    False    False    2017-04-18   \n",
       "4      NCT00001305         False    False     True    2017-04-18   \n",
       "...            ...           ...      ...      ...           ...   \n",
       "40269  NCT05806606         False     True    False    2021-12-10   \n",
       "40270  NCT05806853          True    False     True    2019-10-31   \n",
       "40271  NCT05806866          True    False     True    2023-02-15   \n",
       "40272  NCT05808400          True     True     True    2023-02-14   \n",
       "40273  NCT05808413         False     True    False    2023-02-28   \n",
       "\n",
       "                                                     url  \n",
       "0      https://ClinicalTrials.gov/ProvidedDocs/25/NCT...  \n",
       "1      https://ClinicalTrials.gov/ProvidedDocs/59/NCT...  \n",
       "2      https://ClinicalTrials.gov/ProvidedDocs/77/NCT...  \n",
       "3      https://ClinicalTrials.gov/ProvidedDocs/05/NCT...  \n",
       "4      https://ClinicalTrials.gov/ProvidedDocs/05/NCT...  \n",
       "...                                                  ...  \n",
       "40269  https://ClinicalTrials.gov/ProvidedDocs/06/NCT...  \n",
       "40270  https://ClinicalTrials.gov/ProvidedDocs/53/NCT...  \n",
       "40271  https://ClinicalTrials.gov/ProvidedDocs/66/NCT...  \n",
       "40272  https://ClinicalTrials.gov/ProvidedDocs/00/NCT...  \n",
       "40273  https://ClinicalTrials.gov/ProvidedDocs/13/NCT...  \n",
       "\n",
       "[40274 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_query = text(\n",
    "    f\"\"\"\n",
    "SELECT\n",
    "    provided_documents.nct_id,\n",
    "    provided_documents.has_protocol AS has_protocol,\n",
    "    provided_documents.has_icf AS has_icf,\n",
    "    provided_documents.has_sap AS has_sap,\n",
    "    provided_documents.document_date AS document_date,\n",
    "    provided_documents.url AS url\n",
    "FROM \n",
    "    ctgov.provided_documents\n",
    "ORDER BY provided_documents.nct_id\n",
    ";\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# Execute the SQL query and create a pandas DataFrame from the result\n",
    "df = pd.read_sql_query(\n",
    "    sql_query,\n",
    "    engine,\n",
    "    params={}  # type: ignore\n",
    ")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index(df['nct_id'], inplace=True)\n",
    "# df.drop(columns=['nct_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"ctgov_provided_documents\"\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d\")\n",
    "file_name = f\"{output}_{timestamp}.csv\"\n",
    "# Write the data to output filename\n",
    "df.to_csv(file_name)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40274\n",
      "10667\n",
      "5782\n",
      "8989\n",
      "205\n",
      "13797\n",
      "834\n",
      "40274\n"
     ]
    }
   ],
   "source": [
    "Total = len(df)\n",
    "print(Total)\n",
    "\n",
    "Prot = len(df[(df['has_protocol'] == True) & (df['has_icf'] == False) & (df['has_sap'] == False)])\n",
    "print(Prot)\n",
    "ICF = len(df[(df['has_protocol'] == False) & (df['has_icf'] == True) & (df['has_sap'] == False)])\n",
    "print(ICF)\n",
    "SAP = len(df[(df['has_protocol'] == False) & (df['has_icf'] == False) & (df['has_sap'] == True)])\n",
    "print(SAP)\n",
    "\n",
    "Prot_ICF = len(df[(df['has_protocol'] == True) & (df['has_icf'] == True) & (df['has_sap'] == False)])\n",
    "print(Prot_ICF)\n",
    "Prot_SAP = len(df[(df['has_protocol'] == True) & (df['has_icf'] == False) & (df['has_sap'] == True)])\n",
    "print(Prot_SAP)\n",
    "\n",
    "Prot_ICF_SAP = len(df[(df['has_protocol'] == True) & (df['has_icf'] == True) & (df['has_sap'] == True)])\n",
    "print(Prot_ICF_SAP)\n",
    "\n",
    "\n",
    "sum = Prot + ICF + SAP + Prot_ICF + Prot_SAP + Prot_ICF_SAP \n",
    "print(sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the maximum width for displaying column contents\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# url = df['url'].to_string(index=False)\n",
    "# # file object\n",
    "# with open('url.txt','w') as f:\n",
    "#     # write to file. \n",
    "#     f.write(url)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756a6c882a18466b8d9de1d1572b32db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing rows:   0%|          | 0/40274 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import hashlib\n",
    "import wget\n",
    "from tqdm.auto import tqdm\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "import time\n",
    "\n",
    "# Create 'pdf' folder if it does not exis5\n",
    "if not os.path.exists('pdf'):\n",
    "    os.makedirs('pdf')\n",
    "\n",
    "offset = 690\n",
    "# Assuming 'df' is your pandas DataFrame\n",
    "with tqdm(total=len(df), initial=offset, desc=\"Processing rows\") as pbar:\n",
    "    for index, row in df[offset:].iterrows():\n",
    "# with tqdm(total=len(df), desc=\"Processing rows\") as pbar:\n",
    "#     for index, row in df.iterrows():\n",
    "        # Replace 'NCT' with the actual column name containing the document identifier\n",
    "        doc_name = row['nct_id']\n",
    "        has_protocol = row['has_protocol']\n",
    "        has_icf = row['has_icf']\n",
    "        has_sap = row['has_sap']\n",
    "        # Replace 'url' with the actual column name containing the document URL\n",
    "        url = row['url']\n",
    "\n",
    "        if has_protocol:\n",
    "            if has_icf and has_sap:\n",
    "                doc_name += '_Prot_ICF_SAP.pdf'\n",
    "            elif has_icf:\n",
    "                doc_name += '_Prot_ICF.pdf'\n",
    "            elif has_sap:\n",
    "                doc_name += '_Prot_SAP.pdf'\n",
    "            else:\n",
    "                doc_name += '_Prot.pdf'\n",
    "        else:\n",
    "            if has_icf and has_sap:\n",
    "                doc_name += '_ICF_SAP.pdf'\n",
    "            elif has_icf:\n",
    "                doc_name += '_ICF.pdf'\n",
    "            elif has_sap:\n",
    "                doc_name += '_SAP.pdf'\n",
    "\n",
    "        file_path = os.path.join('pdf', doc_name)\n",
    "        # time.sleep(20)  # Add a delay of 1 second between requests\n",
    "        # # Download and save the URL as PDF\n",
    "        # response = requests.get(url, allow_redirects=True)\n",
    "        # open(file_path, 'wb').write(response.content)\n",
    "        # wget.download(url, file_path)\n",
    "        \n",
    "        cmd = f\"wget -q -c {url} --output-document {file_path}\"\n",
    "        # # cmd = f\"curl --no-progress-meter -o {file_path} {url}\"\n",
    "        try:\n",
    "            os.system(cmd)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {str(e)} of command {cmd}\")\n",
    "            continue\n",
    "        time.sleep(10)\n",
    "        pbar.update(1)\n",
    "        # max_retries = 5\n",
    "        # for _ in range(max_retries):\n",
    "        #     try:\n",
    "        #         os.system(cmd)\n",
    "        #         break  # Break the loop if download is successful\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"An error occurred: {str(e)} for {file_path}\")\n",
    "        #         # Add additional error handling if needed\n",
    "\n",
    "        #     # Sleep for a short time before retrying\n",
    "        #     time.sleep(1)\n",
    "        # pbar.update(1)  # Update progress bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "# import hashlib\n",
    "# from tqdm.auto import tqdm\n",
    "# from requests.packages.urllib3.util.retry import Retry\n",
    "# import time\n",
    "\n",
    "# # Create 'pdf' folder if it does not exist\n",
    "# if not os.path.exists('pdf'):\n",
    "#     os.makedirs('pdf')\n",
    "\n",
    "\n",
    "# # Assuming 'df' is your pandas DataFrame\n",
    "# with tqdm(total=len(df), desc=\"Processing rows\") as pbar:\n",
    "#     for index, row in df.iterrows():\n",
    "#         # Replace 'NCT' with the actual column name containing the document identifier\n",
    "#         doc_name = row['nct_id']\n",
    "#         has_protocol = row['has_protocol']\n",
    "#         has_icf = row['has_icf']\n",
    "#         has_sap = row['has_sap']\n",
    "#         # Replace 'url' with the actual column name containing the document URL\n",
    "#         url = row['url']\n",
    "\n",
    "#         if has_protocol:\n",
    "#             if has_icf and has_sap:\n",
    "#                 doc_name += '_Prot_ICF_SAP.pdf'\n",
    "#             elif has_icf:\n",
    "#                 doc_name += '_Prot_ICF.pdf'\n",
    "#             elif has_sap:\n",
    "#                 doc_name += '_Prot_SAP.pdf'\n",
    "#             else:\n",
    "#                 doc_name += '_Prot.pdf'\n",
    "#         else:\n",
    "#             if has_icf and has_sap:\n",
    "#                 doc_name += '_ICF_SAP.pdf'\n",
    "#             elif has_icf:\n",
    "#                 doc_name += '_ICF.pdf'\n",
    "#             elif has_sap:\n",
    "#                 doc_name += '_SAP.pdf'\n",
    "\n",
    "#         file_path = os.path.join('pdf', doc_name)\n",
    "#         # Check if the file already exists and has the expected file size\n",
    "#         expected_checksum = hashlib.md5(requests.get(url).content).hexdigest()\n",
    "#         time.sleep(4)  # Add a delay of 1 second between requests\n",
    "#         if os.path.exists(file_path):\n",
    "#             with open(file_path, 'rb') as file:\n",
    "#                 existing_checksum = hashlib.md5(file.read()).hexdigest()\n",
    "#             if existing_checksum == expected_checksum:\n",
    "#                 # File already exists and is completely downloaded. Skipping.\n",
    "#                 pbar.update(1)  # Increment the progress bar\n",
    "#                 continue\n",
    "#             else:\n",
    "#                 retries = 3  # Maximum number of retries\n",
    "#                 while retries > 0:\n",
    "#                     try:\n",
    "#                         # Download and save the URL as PDF\n",
    "#                         response = requests.get(url, stream=True)\n",
    "#                         with open(file_path, 'wb') as file:\n",
    "#                             for chunk in response.iter_content(chunk_size=1024):\n",
    "#                                 if chunk:\n",
    "#                                     file.write(chunk)\n",
    "#                         break  # Break out of the retry loop if download is successful\n",
    "#                     except requests.exceptions.RequestException:\n",
    "#                         retries -= 1\n",
    "#                         if retries == 0:\n",
    "#                             print(f\"Failed to download file: {doc_name}\")\n",
    "                \n",
    "#         else:\n",
    "#             retries = 3  # Maximum number of retries\n",
    "#             while retries > 0:\n",
    "#                 try:\n",
    "#                     # Download and save the URL as PDF\n",
    "#                     response = requests.get(url, stream=True)\n",
    "#                     with open(file_path, 'wb') as file:\n",
    "#                         for chunk in response.iter_content(chunk_size=1024):\n",
    "#                             if chunk:\n",
    "#                                 file.write(chunk)\n",
    "#                     break  # Break out of the retry loop if download is successful\n",
    "#                 except requests.exceptions.RequestException:\n",
    "#                     retries -= 1\n",
    "#                     if retries == 0:\n",
    "#                         print(f\"Failed to download file: {doc_name}\")\n",
    "#         pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import requests\n",
    "# import hashlib\n",
    "# from tqdm import tqdm\n",
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# # Create 'pdfs' folder if it does not exist\n",
    "# if not os.path.exists('pdfs'):\n",
    "#     os.makedirs('pdfs')\n",
    "\n",
    "# # Assuming 'df' is your pandas DataFrame\n",
    "# file_tasks = []\n",
    "\n",
    "# for index, row in df.iterrows():\n",
    "#     # Replace 'NCT' with the actual column name containing the document identifier\n",
    "#     doc_name = row['nct_id']\n",
    "#     has_protocol = row['has_protocol']\n",
    "#     has_icf = row['has_icf']\n",
    "#     has_sap = row['has_sap']\n",
    "#     # Replace 'url' with the actual column name containing the document URL\n",
    "#     url = row['url']\n",
    "\n",
    "#     if has_protocol:\n",
    "#         if has_icf and has_sap:\n",
    "#             doc_name += '_Prot_ICF_SAP.pdf'\n",
    "#         elif has_icf:\n",
    "#             doc_name += '_Prot_ICF.pdf'\n",
    "#         elif has_sap:\n",
    "#             doc_name += '_Prot_SAP.pdf'\n",
    "#         else:\n",
    "#             doc_name += '_Prot.pdf'\n",
    "#     else:\n",
    "#         if has_icf and has_sap:\n",
    "#             doc_name += '_ICF_SAP.pdf'\n",
    "#         elif has_icf:\n",
    "#             doc_name += '_ICF.pdf'\n",
    "#         elif has_sap:\n",
    "#             doc_name += '_SAP.pdf'\n",
    "\n",
    "#     file_path = os.path.join('pdfs', doc_name)\n",
    "\n",
    "#     # Check if the file already exists and has the expected file size\n",
    "#     # Check if the file already exists and has the same checksum\n",
    "#     expected_checksum = hashlib.md5(requests.get(url).content).hexdigest()\n",
    "#     if os.path.exists(file_path):\n",
    "#         with open(file_path, 'rb') as file:\n",
    "#             existing_checksum = hashlib.md5(file.read()).hexdigest()\n",
    "#         if existing_checksum == expected_checksum:\n",
    "#             print(\n",
    "#                 f\"File {doc_name} already exists and is completely downloaded. Skipping.\")\n",
    "#             continue\n",
    "\n",
    "#     # Add file download task to the list of tasks\n",
    "#     file_tasks.append((file_path, url, doc_name))\n",
    "\n",
    "# # Download files in parallel using threads\n",
    "\n",
    "\n",
    "# def download_file(file_path, url, doc_name):\n",
    "#     with open(file_path, 'wb') as file:\n",
    "#         response = requests.get(url, stream=True)\n",
    "#         total_size = int(response.headers.get('content-length', 0))\n",
    "#         with tqdm(total=total_size, unit='B', unit_scale=True, desc=f\"Downloading {doc_name}\") as progress_bar:\n",
    "#             for chunk in response.iter_content(chunk_size=1024):\n",
    "#                 if chunk:\n",
    "#                     file.write(chunk)\n",
    "#                     progress_bar.update(len(chunk))\n",
    "\n",
    "\n",
    "# # Create a ThreadPoolExecutor with a maximum number of worker threads\n",
    "# max_workers = os.cpu_count()  # Use the number of available CPU cores\n",
    "# with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "#     # Submit file download tasks to the executor\n",
    "#     futures = [executor.submit(download_file, file_path, url, doc_name)\n",
    "#                for file_path, url, doc_name in file_tasks]\n",
    "\n",
    "#     # Wait for all tasks to complete\n",
    "#     for future in tqdm(futures, desc=\"Waiting for downloads to complete\"):\n",
    "#         future.result()\n",
    "\n",
    "# print(\"All downloads complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
