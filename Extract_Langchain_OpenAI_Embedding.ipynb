{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY=os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "model = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ctgov_studies_20230720.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/qtran/qtran/ctgov/Extract_Langchain_OpenAI_Embedding.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B192.168.1.17/home/qtran/qtran/ctgov/Extract_Langchain_OpenAI_Embedding.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mctgov_studies_20230720.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index_col\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnct_id\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/data/qtran/anaconda3/envs/medqa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/data/qtran/anaconda3/envs/medqa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/data/qtran/anaconda3/envs/medqa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/data/qtran/anaconda3/envs/medqa/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/data/qtran/anaconda3/envs/medqa/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ctgov_studies_20230720.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"csv/ctgov_studies_20230720.csv\", index_col=\"nct_id\")"
=======
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ctgov_studies_20230621.csv\", index_col=\"nct_id\")"
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['brief_title',\n",
       " 'official_title',\n",
       " 'baseline_measurements',\n",
       " 'brief_summaries',\n",
       " 'detailed_descriptions',\n",
       " 'criteria',\n",
       " 'gender',\n",
       " 'minimum_age',\n",
       " 'maximum_age',\n",
       " 'facilities',\n",
       " 'city',\n",
       " 'state',\n",
       " 'zip',\n",
       " 'country',\n",
       " 'recruitment_details',\n",
       " 'pre_assignment_details',\n",
       " 'study_type']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "source": [
    "# Get all columns except overall_status\n",
    "columns = list(df.columns)\n",
    "columns.remove('overall_status')\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"concat\"] = df[columns].apply(lambda x: ' '.join(\n",
    "#     x.astype(str) if x is not None else \"None. \"), axis=1)\n",
    "df[\"concat\"] = df[\"brief_summaries\"]\n",
=======
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brief_title</th>\n",
       "      <th>official_title</th>\n",
       "      <th>overall_status</th>\n",
       "      <th>baseline_measurements</th>\n",
       "      <th>brief_summaries</th>\n",
       "      <th>detailed_descriptions</th>\n",
       "      <th>criteria</th>\n",
       "      <th>gender</th>\n",
       "      <th>minimum_age</th>\n",
       "      <th>maximum_age</th>\n",
       "      <th>facilities</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>zip</th>\n",
       "      <th>country</th>\n",
       "      <th>recruitment_details</th>\n",
       "      <th>pre_assignment_details</th>\n",
       "      <th>study_type</th>\n",
       "      <th>concat</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nct_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NCT00000143</th>\n",
       "      <td>Studies of Ocular Complications of AIDS (SOCA)...</td>\n",
       "      <td>Studies of Ocular Complications of AIDS (SOCA)...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To compare the newest CMV retinitis drug, cido...</td>\n",
       "      <td>Cytomegalovirus (CMV) is among the most freque...</td>\n",
       "      <td>Inclusion criteria:\\n\\nAge 13 years or older\\n...</td>\n",
       "      <td>All</td>\n",
       "      <td>13 Years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University of South Florida, MDC Box 21</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>Texas</td>\n",
       "      <td>94143</td>\n",
       "      <td>United States</td>\n",
       "      <td>June 1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Studies of Ocular Complications of AIDS (SOCA)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00000378</th>\n",
       "      <td>Antidepressant Treatment of Melancholia in Lat...</td>\n",
       "      <td>Antidepressant Treatment of Melancholia in Lat...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The purpose of this study is to compare the sa...</td>\n",
       "      <td>To compare the efficacy and safety of a select...</td>\n",
       "      <td>Inclusion Criteria:\\n\\n-\\n\\nPatients must have...</td>\n",
       "      <td>All</td>\n",
       "      <td>60 Years</td>\n",
       "      <td>95 Years</td>\n",
       "      <td>1051 Riverside Drive</td>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>10032</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Antidepressant Treatment of Melancholia in Lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00000620</th>\n",
       "      <td>Action to Control Cardiovascular Risk in Diabe...</td>\n",
       "      <td>Action to Control Cardiovascular Risk in Diabe...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The purpose of this study is to prevent major ...</td>\n",
       "      <td>BACKGROUND:\\n\\nCurrently, about 17 million Ame...</td>\n",
       "      <td>Inclusion Criteria:\\n\\nDiagnosed with type 2 d...</td>\n",
       "      <td>All</td>\n",
       "      <td>40 Years</td>\n",
       "      <td>79 Years</td>\n",
       "      <td>Wake Forest University</td>\n",
       "      <td>Winston-Salem</td>\n",
       "      <td>Washington</td>\n",
       "      <td>98195</td>\n",
       "      <td>United States</td>\n",
       "      <td>All participants had established type 2 diabet...</td>\n",
       "      <td>Eligible participants provided evidence of abi...</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Action to Control Cardiovascular Risk in Diabe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00001151</th>\n",
       "      <td>Studies With 1,25-Dihydroxycholecalciferol</td>\n",
       "      <td>Studies With 1,25-Dihydroxycholecalciferol</td>\n",
       "      <td>Terminated</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vitamin D in the diet undergoes changes in the...</td>\n",
       "      <td>Patients with extreme resistance to 1,25-dihyd...</td>\n",
       "      <td>INCLUSION CRITERIA:\\n\\nPatients with hereditar...</td>\n",
       "      <td>All</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Institutes of Health Clinical Center,...</td>\n",
       "      <td>Bethesda</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>20892</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Studies With 1,25-Dihydroxycholecalciferol Stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT00001213</th>\n",
       "      <td>Cysteamine Eye Drops to Treat Corneal Crystals...</td>\n",
       "      <td>Trial of Topical Cysteamine in the Treatment o...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>Although 328 participants were initially enrol...</td>\n",
       "      <td>Cystinosis is an inherited disease that result...</td>\n",
       "      <td>Protocol 86-EI-0062 began as a randomized, dou...</td>\n",
       "      <td>INCLUSION CRITERIA:\\n\\nPatients must have a do...</td>\n",
       "      <td>All</td>\n",
       "      <td>2 Years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Institutes of Health Clinical Center,...</td>\n",
       "      <td>Bethesda</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>20892</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Cysteamine Eye Drops to Treat Corneal Crystals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT05490771</th>\n",
       "      <td>Testing Copanlisib as a Potential Targeted Tre...</td>\n",
       "      <td>Phase II Study of Copanlisib in Patients With ...</td>\n",
       "      <td>Active, not recruiting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This phase II MATCH treatment trial identifies...</td>\n",
       "      <td>PRIMARY OBJECTIVE:\\n\\nI. To evaluate the propo...</td>\n",
       "      <td>Inclusion Criteria:\\n\\nPatients must have met ...</td>\n",
       "      <td>All</td>\n",
       "      <td>18 Years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECOG-ACRIN Cancer Research Group</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>19103</td>\n",
       "      <td>United States</td>\n",
       "      <td>Subprotocol Z1F was activated on June 20, 2018...</td>\n",
       "      <td>The PIK3CA mutations status was determined by ...</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Testing Copanlisib as a Potential Targeted Tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT05502081</th>\n",
       "      <td>Clinical Study to Compare Efficacy and Safety ...</td>\n",
       "      <td>Clinical Study to Evaluate the Possible Effica...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0. Uninfected\\n\\nAmbulatory mild disease\\n\\nAs...</td>\n",
       "      <td>Introduction:\\n\\nCorona Virus induced disease ...</td>\n",
       "      <td>I. INTRODUCTION\\n\\n1.1. COVID-19 overview and ...</td>\n",
       "      <td>Inclusion Criteria:\\n\\nage more than 12 years ...</td>\n",
       "      <td>All</td>\n",
       "      <td>12 Years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>El-gomhoria St</td>\n",
       "      <td>Mansoura</td>\n",
       "      <td>El-dkhalia</td>\n",
       "      <td>050</td>\n",
       "      <td>Egypt</td>\n",
       "      <td>from 1/11/2021 to 29/5/2022 at isolation hospi...</td>\n",
       "      <td>assignment is applied after admission of parti...</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Clinical Study to Compare Efficacy and Safety ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT05594173</th>\n",
       "      <td>Chewing and Oral Processing of Solid Food</td>\n",
       "      <td>Chewing and Oral Processing of Solid Food in H...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Food texture modification is commonly used as ...</td>\n",
       "      <td>Aim: To explore chewing and oral processing be...</td>\n",
       "      <td>Inclusion Criteria:\\n\\nHealthy adults under ag...</td>\n",
       "      <td>All</td>\n",
       "      <td>18 Years</td>\n",
       "      <td>60 Years</td>\n",
       "      <td>Toronto Rehabilitation Institute - University ...</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>M5G 2A2</td>\n",
       "      <td>Canada</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Observational</td>\n",
       "      <td>Chewing and Oral Processing of Solid Food Chew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT05607147</th>\n",
       "      <td>Rutgers Pilot for Dental Health Care Worker SA...</td>\n",
       "      <td>Rutgers Pilot for Pragmatic Return to Effectiv...</td>\n",
       "      <td>Active, not recruiting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10 asymptomatic DHCWs in the Oral Medicine cli...</td>\n",
       "      <td>10 asymptomatic DHCWs in the Oral Medicine cli...</td>\n",
       "      <td>Inclusion Criteria:\\n\\nDental healthcare worke...</td>\n",
       "      <td>All</td>\n",
       "      <td>18 Years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rutgers School of Dental Medicine</td>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>07103</td>\n",
       "      <td>United States</td>\n",
       "      <td>10 asymptomatic DHCWs in the Oral Medicine cli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>Rutgers Pilot for Dental Health Care Worker SA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCT05736861</th>\n",
       "      <td>ACTIV-6: COVID-19 Study of Repurposed Medicati...</td>\n",
       "      <td>ACTIV-6: COVID-19 Outpatient Randomized Trial ...</td>\n",
       "      <td>Completed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The purpose of this study is to evaluate the e...</td>\n",
       "      <td>Severe acute respiratory syndrome coronavirus ...</td>\n",
       "      <td>Inclusion Criteria:\\n\\nCompleted Informed Cons...</td>\n",
       "      <td>All</td>\n",
       "      <td>30 Years</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Well Pharma Medical Research</td>\n",
       "      <td>Yonkers</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>94304</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Interventional</td>\n",
       "      <td>ACTIV-6: COVID-19 Study of Repurposed Medicati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34983 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   brief_title  \\\n",
       "nct_id                                                           \n",
       "NCT00000143  Studies of Ocular Complications of AIDS (SOCA)...   \n",
       "NCT00000378  Antidepressant Treatment of Melancholia in Lat...   \n",
       "NCT00000620  Action to Control Cardiovascular Risk in Diabe...   \n",
       "NCT00001151         Studies With 1,25-Dihydroxycholecalciferol   \n",
       "NCT00001213  Cysteamine Eye Drops to Treat Corneal Crystals...   \n",
       "...                                                        ...   \n",
       "NCT05490771  Testing Copanlisib as a Potential Targeted Tre...   \n",
       "NCT05502081  Clinical Study to Compare Efficacy and Safety ...   \n",
       "NCT05594173          Chewing and Oral Processing of Solid Food   \n",
       "NCT05607147  Rutgers Pilot for Dental Health Care Worker SA...   \n",
       "NCT05736861  ACTIV-6: COVID-19 Study of Repurposed Medicati...   \n",
       "\n",
       "                                                official_title  \\\n",
       "nct_id                                                           \n",
       "NCT00000143  Studies of Ocular Complications of AIDS (SOCA)...   \n",
       "NCT00000378  Antidepressant Treatment of Melancholia in Lat...   \n",
       "NCT00000620  Action to Control Cardiovascular Risk in Diabe...   \n",
       "NCT00001151         Studies With 1,25-Dihydroxycholecalciferol   \n",
       "NCT00001213  Trial of Topical Cysteamine in the Treatment o...   \n",
       "...                                                        ...   \n",
       "NCT05490771  Phase II Study of Copanlisib in Patients With ...   \n",
       "NCT05502081  Clinical Study to Evaluate the Possible Effica...   \n",
       "NCT05594173  Chewing and Oral Processing of Solid Food in H...   \n",
       "NCT05607147  Rutgers Pilot for Pragmatic Return to Effectiv...   \n",
       "NCT05736861  ACTIV-6: COVID-19 Outpatient Randomized Trial ...   \n",
       "\n",
       "                     overall_status  \\\n",
       "nct_id                                \n",
       "NCT00000143               Completed   \n",
       "NCT00000378               Completed   \n",
       "NCT00000620               Completed   \n",
       "NCT00001151              Terminated   \n",
       "NCT00001213               Completed   \n",
       "...                             ...   \n",
       "NCT05490771  Active, not recruiting   \n",
       "NCT05502081               Completed   \n",
       "NCT05594173               Completed   \n",
       "NCT05607147  Active, not recruiting   \n",
       "NCT05736861               Completed   \n",
       "\n",
       "                                         baseline_measurements  \\\n",
       "nct_id                                                           \n",
       "NCT00000143                                                NaN   \n",
       "NCT00000378                                                NaN   \n",
       "NCT00000620                                                NaN   \n",
       "NCT00001151                                                NaN   \n",
       "NCT00001213  Although 328 participants were initially enrol...   \n",
       "...                                                        ...   \n",
       "NCT05490771                                                NaN   \n",
       "NCT05502081  0. Uninfected\\n\\nAmbulatory mild disease\\n\\nAs...   \n",
       "NCT05594173                                                NaN   \n",
       "NCT05607147                                                NaN   \n",
       "NCT05736861                                                NaN   \n",
       "\n",
       "                                               brief_summaries  \\\n",
       "nct_id                                                           \n",
       "NCT00000143  To compare the newest CMV retinitis drug, cido...   \n",
       "NCT00000378  The purpose of this study is to compare the sa...   \n",
       "NCT00000620  The purpose of this study is to prevent major ...   \n",
       "NCT00001151  Vitamin D in the diet undergoes changes in the...   \n",
       "NCT00001213  Cystinosis is an inherited disease that result...   \n",
       "...                                                        ...   \n",
       "NCT05490771  This phase II MATCH treatment trial identifies...   \n",
       "NCT05502081  Introduction:\\n\\nCorona Virus induced disease ...   \n",
       "NCT05594173  Food texture modification is commonly used as ...   \n",
       "NCT05607147  10 asymptomatic DHCWs in the Oral Medicine cli...   \n",
       "NCT05736861  The purpose of this study is to evaluate the e...   \n",
       "\n",
       "                                         detailed_descriptions  \\\n",
       "nct_id                                                           \n",
       "NCT00000143  Cytomegalovirus (CMV) is among the most freque...   \n",
       "NCT00000378  To compare the efficacy and safety of a select...   \n",
       "NCT00000620  BACKGROUND:\\n\\nCurrently, about 17 million Ame...   \n",
       "NCT00001151  Patients with extreme resistance to 1,25-dihyd...   \n",
       "NCT00001213  Protocol 86-EI-0062 began as a randomized, dou...   \n",
       "...                                                        ...   \n",
       "NCT05490771  PRIMARY OBJECTIVE:\\n\\nI. To evaluate the propo...   \n",
       "NCT05502081  I. INTRODUCTION\\n\\n1.1. COVID-19 overview and ...   \n",
       "NCT05594173  Aim: To explore chewing and oral processing be...   \n",
       "NCT05607147  10 asymptomatic DHCWs in the Oral Medicine cli...   \n",
       "NCT05736861  Severe acute respiratory syndrome coronavirus ...   \n",
       "\n",
       "                                                      criteria gender  \\\n",
       "nct_id                                                                  \n",
       "NCT00000143  Inclusion criteria:\\n\\nAge 13 years or older\\n...    All   \n",
       "NCT00000378  Inclusion Criteria:\\n\\n-\\n\\nPatients must have...    All   \n",
       "NCT00000620  Inclusion Criteria:\\n\\nDiagnosed with type 2 d...    All   \n",
       "NCT00001151  INCLUSION CRITERIA:\\n\\nPatients with hereditar...    All   \n",
       "NCT00001213  INCLUSION CRITERIA:\\n\\nPatients must have a do...    All   \n",
       "...                                                        ...    ...   \n",
       "NCT05490771  Inclusion Criteria:\\n\\nPatients must have met ...    All   \n",
       "NCT05502081  Inclusion Criteria:\\n\\nage more than 12 years ...    All   \n",
       "NCT05594173  Inclusion Criteria:\\n\\nHealthy adults under ag...    All   \n",
       "NCT05607147  Inclusion Criteria:\\n\\nDental healthcare worke...    All   \n",
       "NCT05736861  Inclusion Criteria:\\n\\nCompleted Informed Cons...    All   \n",
       "\n",
       "            minimum_age maximum_age  \\\n",
       "nct_id                                \n",
       "NCT00000143    13 Years         NaN   \n",
       "NCT00000378    60 Years    95 Years   \n",
       "NCT00000620    40 Years    79 Years   \n",
       "NCT00001151         NaN         NaN   \n",
       "NCT00001213     2 Years         NaN   \n",
       "...                 ...         ...   \n",
       "NCT05490771    18 Years         NaN   \n",
       "NCT05502081    12 Years         NaN   \n",
       "NCT05594173    18 Years    60 Years   \n",
       "NCT05607147    18 Years         NaN   \n",
       "NCT05736861    30 Years         NaN   \n",
       "\n",
       "                                                    facilities           city  \\\n",
       "nct_id                                                                          \n",
       "NCT00000143            University of South Florida, MDC Box 21          Tampa   \n",
       "NCT00000378                               1051 Riverside Drive       New York   \n",
       "NCT00000620                             Wake Forest University  Winston-Salem   \n",
       "NCT00001151  National Institutes of Health Clinical Center,...       Bethesda   \n",
       "NCT00001213  National Institutes of Health Clinical Center,...       Bethesda   \n",
       "...                                                        ...            ...   \n",
       "NCT05490771                   ECOG-ACRIN Cancer Research Group   Philadelphia   \n",
       "NCT05502081                                     El-gomhoria St       Mansoura   \n",
       "NCT05594173  Toronto Rehabilitation Institute - University ...        Toronto   \n",
       "NCT05607147                  Rutgers School of Dental Medicine         Newark   \n",
       "NCT05736861                       Well Pharma Medical Research        Yonkers   \n",
       "\n",
       "                    state      zip        country  \\\n",
       "nct_id                                              \n",
       "NCT00000143         Texas    94143  United States   \n",
       "NCT00000378      New York    10032  United States   \n",
       "NCT00000620    Washington    98195  United States   \n",
       "NCT00001151      Maryland    20892  United States   \n",
       "NCT00001213      Maryland    20892  United States   \n",
       "...                   ...      ...            ...   \n",
       "NCT05490771  Pennsylvania    19103  United States   \n",
       "NCT05502081    El-dkhalia      050          Egypt   \n",
       "NCT05594173       Ontario  M5G 2A2         Canada   \n",
       "NCT05607147    New Jersey    07103  United States   \n",
       "NCT05736861      Virginia    94304  United States   \n",
       "\n",
       "                                           recruitment_details  \\\n",
       "nct_id                                                           \n",
       "NCT00000143                                          June 1997   \n",
       "NCT00000378                                                NaN   \n",
       "NCT00000620  All participants had established type 2 diabet...   \n",
       "NCT00001151                                                NaN   \n",
       "NCT00001213                                                NaN   \n",
       "...                                                        ...   \n",
       "NCT05490771  Subprotocol Z1F was activated on June 20, 2018...   \n",
       "NCT05502081  from 1/11/2021 to 29/5/2022 at isolation hospi...   \n",
       "NCT05594173                                                NaN   \n",
       "NCT05607147  10 asymptomatic DHCWs in the Oral Medicine cli...   \n",
       "NCT05736861                                                NaN   \n",
       "\n",
       "                                        pre_assignment_details  \\\n",
       "nct_id                                                           \n",
       "NCT00000143                                                NaN   \n",
       "NCT00000378                                                NaN   \n",
       "NCT00000620  Eligible participants provided evidence of abi...   \n",
       "NCT00001151                                                NaN   \n",
       "NCT00001213                                                NaN   \n",
       "...                                                        ...   \n",
       "NCT05490771  The PIK3CA mutations status was determined by ...   \n",
       "NCT05502081  assignment is applied after admission of parti...   \n",
       "NCT05594173                                                NaN   \n",
       "NCT05607147                                                NaN   \n",
       "NCT05736861                                                NaN   \n",
       "\n",
       "                 study_type                                             concat  \n",
       "nct_id                                                                          \n",
       "NCT00000143  Interventional  Studies of Ocular Complications of AIDS (SOCA)...  \n",
       "NCT00000378  Interventional  Antidepressant Treatment of Melancholia in Lat...  \n",
       "NCT00000620  Interventional  Action to Control Cardiovascular Risk in Diabe...  \n",
       "NCT00001151  Interventional  Studies With 1,25-Dihydroxycholecalciferol Stu...  \n",
       "NCT00001213  Interventional  Cysteamine Eye Drops to Treat Corneal Crystals...  \n",
       "...                     ...                                                ...  \n",
       "NCT05490771  Interventional  Testing Copanlisib as a Potential Targeted Tre...  \n",
       "NCT05502081  Interventional  Clinical Study to Compare Efficacy and Safety ...  \n",
       "NCT05594173   Observational  Chewing and Oral Processing of Solid Food Chew...  \n",
       "NCT05607147  Interventional  Rutgers Pilot for Dental Health Care Worker SA...  \n",
       "NCT05736861  Interventional  ACTIV-6: COVID-19 Study of Repurposed Medicati...  \n",
       "\n",
       "[34983 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df[\"concat\"] = df[columns].apply(lambda x: ' '.join(\n",
    "    x.astype(str) if x is not None else \"None. \"), axis=1)\n",
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
    "df\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 7,
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def _generate_embedding(\n",
    "    text=None,\n",
    "    model=None,\n",
    "    amount=0,\n",
    "):\n",
    "    assert model is not None\n",
    "    embedding = model.embed_documents([text])\n",
    "    time.sleep(amount)\n",
    "    embedding = np.array(embedding).squeeze()\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0246bcd996e842d4ae25341d4ad9ffb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7becfc292d498dfc938364839b3e50ca in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7becfc292d498dfc938364839b3e50ca in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7becfc292d498dfc938364839b3e50ca in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 03:57:53 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30036', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '7becfc292d498dfc938364839b3e50ca', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da953bb2bd63fcf-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 039d9cd718b914fcec87dbd238ae5069 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 039d9cd718b914fcec87dbd238ae5069 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 039d9cd718b914fcec87dbd238ae5069 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 04:15:23 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30021', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '039d9cd718b914fcec87dbd238ae5069', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da96d5e0f0640a0-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cbdaf4dde5959d890e320d4aee59d3ad in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cbdaf4dde5959d890e320d4aee59d3ad in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cbdaf4dde5959d890e320d4aee59d3ad in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 04:25:18 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30023', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'cbdaf4dde5959d890e320d4aee59d3ad', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da97be3cb7491cb-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6ef9bb4d12f1df0d231f1a1af743f3f in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6ef9bb4d12f1df0d231f1a1af743f3f in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6ef9bb4d12f1df0d231f1a1af743f3f in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 04:27:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30020', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'a6ef9bb4d12f1df0d231f1a1af743f3f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da97ed7399191cb-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3e9cdc6bf307308aed46b15b7e79151 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3e9cdc6bf307308aed46b15b7e79151 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e3e9cdc6bf307308aed46b15b7e79151 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 04:36:51 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30063', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'e3e9cdc6bf307308aed46b15b7e79151', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da98ccefdd64062-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c34f092bdda84acedffdb2135cb1b5f4 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c34f092bdda84acedffdb2135cb1b5f4 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c34f092bdda84acedffdb2135cb1b5f4 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 04:47:38 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30047', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'c34f092bdda84acedffdb2135cb1b5f4', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da99c9bcd824085-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cdc5010eb023eafa40f82650b103049a in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cdc5010eb023eafa40f82650b103049a in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cdc5010eb023eafa40f82650b103049a in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 05:01:57 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30017', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'cdc5010eb023eafa40f82650b103049a', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da9b19268273e3d-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6c092756f40a046e090bfbe87c5a292 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6c092756f40a046e090bfbe87c5a292 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID a6c092756f40a046e090bfbe87c5a292 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 05:46:32 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30081', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'a6c092756f40a046e090bfbe87c5a292', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7da9f2e10bcd4727-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11763c685d1678c015a07ee7cddb93e7 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11763c685d1678c015a07ee7cddb93e7 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11763c685d1678c015a07ee7cddb93e7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 05:56:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30017', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '11763c685d1678c015a07ee7cddb93e7', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daa00fd795c4918-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1e0ad43465bbcb9887973104c1d19737 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1e0ad43465bbcb9887973104c1d19737 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1e0ad43465bbcb9887973104c1d19737 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 06:09:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30024', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '1e0ad43465bbcb9887973104c1d19737', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daa14df9d3c40b5-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cf3cc1a414dce71e3e19a5b062b2a6d8 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cf3cc1a414dce71e3e19a5b062b2a6d8 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cf3cc1a414dce71e3e19a5b062b2a6d8 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 06:30:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30019', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'cf3cc1a414dce71e3e19a5b062b2a6d8', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daa33093a713ff4-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9245c54e4ffd6d706d6d28202863b830 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9245c54e4ffd6d706d6d28202863b830 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9245c54e4ffd6d706d6d28202863b830 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 06:31:50 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30027', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '9245c54e4ffd6d706d6d28202863b830', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daa354278cf3ff4-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9438a63df3e39bdb31af0fb3e8c2b6fc in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9438a63df3e39bdb31af0fb3e8c2b6fc in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9438a63df3e39bdb31af0fb3e8c2b6fc in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 06:47:29 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30020', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '9438a63df3e39bdb31af0fb3e8c2b6fc', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daa4c2c28dc4064-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b6620cae44d8684d5e2aefaaf3f1387 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b6620cae44d8684d5e2aefaaf3f1387 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 6b6620cae44d8684d5e2aefaaf3f1387 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 07:23:16 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30055', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '6b6620cae44d8684d5e2aefaaf3f1387', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daa808a0f72a077-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e7ca19b219700b388ae68a9a49cde7a7 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e7ca19b219700b388ae68a9a49cde7a7 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID e7ca19b219700b388ae68a9a49cde7a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 07:32:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30019', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'e7ca19b219700b388ae68a9a49cde7a7', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daa8e2d1d1c4d69-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f5f0b4b537145008e8baa680626ab298 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f5f0b4b537145008e8baa680626ab298 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f5f0b4b537145008e8baa680626ab298 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 07:49:03 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30060', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'f5f0b4b537145008e8baa680626ab298', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daaa65d286a882c-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID df829843234f12c05df03211004a6572 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID df829843234f12c05df03211004a6572 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID df829843234f12c05df03211004a6572 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 07:52:34 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30116', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'df829843234f12c05df03211004a6572', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daaab829c799fb3-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5bd9c333555dc72918c4cb7aef2e472d in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5bd9c333555dc72918c4cb7aef2e472d in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5bd9c333555dc72918c4cb7aef2e472d in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:02:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30118', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '5bd9c333555dc72918c4cb7aef2e472d', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daaba643fc29f9e-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 53491a5c2882a9457ce4b216e95d444f in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 53491a5c2882a9457ce4b216e95d444f in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 53491a5c2882a9457ce4b216e95d444f in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:04:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30015', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '53491a5c2882a9457ce4b216e95d444f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daabc702f5f9f9e-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 487f68c4f277232a8d4f842a7d1bebd2 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 487f68c4f277232a8d4f842a7d1bebd2 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 487f68c4f277232a8d4f842a7d1bebd2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:07:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '35485', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '487f68c4f277232a8d4f842a7d1bebd2', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daac0c5ddbe44c7-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f99ad3c40e2b2fd371b8520a1cf0937 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f99ad3c40e2b2fd371b8520a1cf0937 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7f99ad3c40e2b2fd371b8520a1cf0937 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:21:14 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30016', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '7f99ad3c40e2b2fd371b8520a1cf0937', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daad57e8e9e6bf3-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7585e670682b6f021bb8ff8dc85ae0fe in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7585e670682b6f021bb8ff8dc85ae0fe in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7585e670682b6f021bb8ff8dc85ae0fe in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:27:41 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30019', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '7585e670682b6f021bb8ff8dc85ae0fe', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daadef328aa3e61-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0290b06ac64bd07dfa0099bfa9cfde3 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0290b06ac64bd07dfa0099bfa9cfde3 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f0290b06ac64bd07dfa0099bfa9cfde3 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:31:16 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30020', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'f0290b06ac64bd07dfa0099bfa9cfde3', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daae432ff4d40de-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9de7bbe2f4a95f35d346990392ee9b89 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9de7bbe2f4a95f35d346990392ee9b89 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9de7bbe2f4a95f35d346990392ee9b89 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:31:58 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30052', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '9de7bbe2f4a95f35d346990392ee9b89', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daae53bbf6c40de-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 19484880ed29cf9d3152bb3194c86273 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 19484880ed29cf9d3152bb3194c86273 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 19484880ed29cf9d3152bb3194c86273 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:40:16 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30017', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '19484880ed29cf9d3152bb3194c86273', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daaf1625b004b92-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 676231353843560e96c2642d0d68c899 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 676231353843560e96c2642d0d68c899 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 676231353843560e96c2642d0d68c899 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:42:53 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30018', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '676231353843560e96c2642d0d68c899', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daaf5387b779fb5-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c6879d7480e332997a0bd8c690fa3d1 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c6879d7480e332997a0bd8c690fa3d1 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3c6879d7480e332997a0bd8c690fa3d1 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:47:30 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30154', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '3c6879d7480e332997a0bd8c690fa3d1', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daafbf93d393f5a-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99b7fec8666b13f8c5b776224e1eb659 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99b7fec8666b13f8c5b776224e1eb659 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 99b7fec8666b13f8c5b776224e1eb659 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:49:29 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '32404', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '99b7fec8666b13f8c5b776224e1eb659', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daafed16b863f5a-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c8651f3edf12017316ab35c943d7c539 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c8651f3edf12017316ab35c943d7c539 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID c8651f3edf12017316ab35c943d7c539 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:50:32 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30022', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'c8651f3edf12017316ab35c943d7c539', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab006e0cf33f67-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 72092c4c2d187028d517cb8e86c7e379 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 72092c4c2d187028d517cb8e86c7e379 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 72092c4c2d187028d517cb8e86c7e379 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:52:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '33759', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '72092c4c2d187028d517cb8e86c7e379', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab03a62c313f67-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5630dee81c0eb4681991f703806ada1a in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5630dee81c0eb4681991f703806ada1a in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 5630dee81c0eb4681991f703806ada1a in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 08:56:56 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30046', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '5630dee81c0eb4681991f703806ada1a', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab09c8c8314018-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 074c076a1c0ced0d2a678c79509187b9 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 074c076a1c0ced0d2a678c79509187b9 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 074c076a1c0ced0d2a678c79509187b9 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 09:00:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30018', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '074c076a1c0ced0d2a678c79509187b9', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab0e6bebf0a08d-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: HTTP code 502 from API (<html>\n",
      "<head><title>502 Bad Gateway</title></head>\n",
      "<body>\n",
      "<center><h1>502 Bad Gateway</h1></center>\n",
      "<hr><center>cloudflare</center>\n",
      "</body>\n",
      "</html>\n",
      ").\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 960b269d2a8c0aadeed853f80754e373 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 960b269d2a8c0aadeed853f80754e373 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 960b269d2a8c0aadeed853f80754e373 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 09:21:56 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30037', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '960b269d2a8c0aadeed853f80754e373', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab2e67dcbf89b6-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ff5905b954fecfd603f5b81c2ec47a7 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ff5905b954fecfd603f5b81c2ec47a7 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7ff5905b954fecfd603f5b81c2ec47a7 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 09:24:36 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30025', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '7ff5905b954fecfd603f5b81c2ec47a7', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab32516a4646a3-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a11265f984835c9e6ec90d12f5efdbf in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a11265f984835c9e6ec90d12f5efdbf in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 1a11265f984835c9e6ec90d12f5efdbf in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 09:28:27 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30037', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '1a11265f984835c9e6ec90d12f5efdbf', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab37f5db9440c6-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb5e80d6c41a00b25a7854b0b85703b5 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb5e80d6c41a00b25a7854b0b85703b5 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID cb5e80d6c41a00b25a7854b0b85703b5 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 09:31:14 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30024', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'cb5e80d6c41a00b25a7854b0b85703b5', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab3c08baa83de2-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 096c02ed0c6c7b6415aec3fbaacf0b2f in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 096c02ed0c6c7b6415aec3fbaacf0b2f in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 096c02ed0c6c7b6415aec3fbaacf0b2f in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 09:32:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30018', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '096c02ed0c6c7b6415aec3fbaacf0b2f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab3d47f8023de2-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8859dfb93e6b0707f2209888cf84ad2 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8859dfb93e6b0707f2209888cf84ad2 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b8859dfb93e6b0707f2209888cf84ad2 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 09:34:31 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30036', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'b8859dfb93e6b0707f2209888cf84ad2', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab40db89a344b3-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75be73ff27bf055a4080d64b794f9818 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75be73ff27bf055a4080d64b794f9818 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 75be73ff27bf055a4080d64b794f9818 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:01:36 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30035', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '75be73ff27bf055a4080d64b794f9818', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab68843c7740dd-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 05bee1cd9518569e8f6201782361823d in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 05bee1cd9518569e8f6201782361823d in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 05bee1cd9518569e8f6201782361823d in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:04:08 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30029', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '05bee1cd9518569e8f6201782361823d', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab6c3bdb623da4-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 157561ca13af814e02f00adbd595aa2e in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 157561ca13af814e02f00adbd595aa2e in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 157561ca13af814e02f00adbd595aa2e in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:07:52 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30234', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '157561ca13af814e02f00adbd595aa2e', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab71afba0e404d-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d14c05ed94cbf67aeba44c4e2bcaad6 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d14c05ed94cbf67aeba44c4e2bcaad6 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9d14c05ed94cbf67aeba44c4e2bcaad6 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:10:49 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30038', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '9d14c05ed94cbf67aeba44c4e2bcaad6', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab76063a99465b-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9cde2c2430eb4210f5703bdef4bbb94e in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9cde2c2430eb4210f5703bdef4bbb94e in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9cde2c2430eb4210f5703bdef4bbb94e in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:13:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30022', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '9cde2c2430eb4210f5703bdef4bbb94e', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab79be48533d7b-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 77d018e30ab69f181fe215154acadb1f in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 77d018e30ab69f181fe215154acadb1f in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 77d018e30ab69f181fe215154acadb1f in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:21:13 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30018', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '77d018e30ab69f181fe215154acadb1f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dab8541897440ce-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b0091c46384b6138ce7730e745ebf38 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b0091c46384b6138ce7730e745ebf38 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 9b0091c46384b6138ce7730e745ebf38 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:44:37 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30019', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '9b0091c46384b6138ce7730e745ebf38', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daba78a785b44ae-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11fdfeae15808657f5c6d535e76fec26 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11fdfeae15808657f5c6d535e76fec26 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 11fdfeae15808657f5c6d535e76fec26 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 10:45:12 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30030', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '11fdfeae15808657f5c6d535e76fec26', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daba860ec2e44ae-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 52545d059f6a4d65e97a8c275d257a03 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 52545d059f6a4d65e97a8c275d257a03 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 52545d059f6a4d65e97a8c275d257a03 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:14:41 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30035', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '52545d059f6a4d65e97a8c275d257a03', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dabd3942a204aad-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd20fe33b26b65ba50e972bbe33aa31d in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd20fe33b26b65ba50e972bbe33aa31d in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fd20fe33b26b65ba50e972bbe33aa31d in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:37:35 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30096', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'fd20fe33b26b65ba50e972bbe33aa31d', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dabf51edd9944ab-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b212d822e22f6fba8a0853ad719d3592 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b212d822e22f6fba8a0853ad719d3592 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b212d822e22f6fba8a0853ad719d3592 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:44:05 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30034', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'b212d822e22f6fba8a0853ad719d3592', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dabfea78ffa4923-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3a6599d341433191c98d1159ff5b463 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3a6599d341433191c98d1159ff5b463 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d3a6599d341433191c98d1159ff5b463 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:46:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30017', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'd3a6599d341433191c98d1159ff5b463', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac01cedae54906-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fdba2b9818667dfb677f7c1c70785e3b in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fdba2b9818667dfb677f7c1c70785e3b in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID fdba2b9818667dfb677f7c1c70785e3b in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:48:14 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30013', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'fdba2b9818667dfb677f7c1c70785e3b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac04b9dc1f4906-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d285311b6b0a28cdbfe8e32f7ba23c16 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d285311b6b0a28cdbfe8e32f7ba23c16 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID d285311b6b0a28cdbfe8e32f7ba23c16 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:52:14 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30064', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'd285311b6b0a28cdbfe8e32f7ba23c16', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac0a91dfb340b4-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3914959fd40e8f511ef062d7af64ccba in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3914959fd40e8f511ef062d7af64ccba in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3914959fd40e8f511ef062d7af64ccba in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:52:48 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30022', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '3914959fd40e8f511ef062d7af64ccba', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac0b68f80d40b4-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 28fc41b2a9fd6e90ebdb05903f2a8357 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 28fc41b2a9fd6e90ebdb05903f2a8357 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 28fc41b2a9fd6e90ebdb05903f2a8357 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 11:55:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30071', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '28fc41b2a9fd6e90ebdb05903f2a8357', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac0ee3e8ae40b4-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7599cdd970ee36655463d73125ee9e4b in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7599cdd970ee36655463d73125ee9e4b in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 7599cdd970ee36655463d73125ee9e4b in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 12:20:12 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30028', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '7599cdd970ee36655463d73125ee9e4b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac338a7db54079-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f776f6405263fb58244582dc3293f34b in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f776f6405263fb58244582dc3293f34b in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID f776f6405263fb58244582dc3293f34b in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 12:21:14 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30018', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'f776f6405263fb58244582dc3293f34b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac35111dc544ad-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dec6a7eece18a959e241e9f88ed47a0f in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dec6a7eece18a959e241e9f88ed47a0f in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID dec6a7eece18a959e241e9f88ed47a0f in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 12:26:41 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30012', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'dec6a7eece18a959e241e9f88ed47a0f', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac3d09bb4a4028-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eba4a67dd331f25654ffb1386a64e246 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eba4a67dd331f25654ffb1386a64e246 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID eba4a67dd331f25654ffb1386a64e246 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 12:28:12 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30145', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'eba4a67dd331f25654ffb1386a64e246', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac3f44e84b49c0-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ddd676c5e3b6866a3eca6fb3317f3880 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ddd676c5e3b6866a3eca6fb3317f3880 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID ddd676c5e3b6866a3eca6fb3317f3880 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 12:39:15 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30029', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'ddd676c5e3b6866a3eca6fb3317f3880', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac4f76be348971-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bdec98f3472eb27aa6bb3713c780e49b in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bdec98f3472eb27aa6bb3713c780e49b in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID bdec98f3472eb27aa6bb3713c780e49b in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 12:40:46 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30108', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'bdec98f3472eb27aa6bb3713c780e49b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dac51abdfd291c0-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 012a343ed435ce67d432de1e4a03691a in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 012a343ed435ce67d432de1e4a03691a in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 012a343ed435ce67d432de1e4a03691a in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 15:44:02 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30029', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '012a343ed435ce67d432de1e4a03691a', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7dad5e249ad09fbb-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 012f20095fbf0e4f814eae4403d4535b in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 012f20095fbf0e4f814eae4403d4535b in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 012f20095fbf0e4f814eae4403d4535b in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 21 Jun 2023 19:52:46 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30014', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '012f20095fbf0e4f814eae4403d4535b', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7daeca7c5c06ab43-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 918da949b11ceffc756298bab9763a96 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 918da949b11ceffc756298bab9763a96 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 918da949b11ceffc756298bab9763a96 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Thu, 22 Jun 2023 12:34:23 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30014', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '918da949b11ceffc756298bab9763a96', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7db485b39f9e885b-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2dbe28bdcea1bd371970a4a1b3ca1f61 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2dbe28bdcea1bd371970a4a1b3ca1f61 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 2dbe28bdcea1bd371970a4a1b3ca1f61 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Thu, 22 Jun 2023 14:18:47 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30012', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '2dbe28bdcea1bd371970a4a1b3ca1f61', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7db51db5be143e53-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 76104c142fb25215bdfaabc91607ffbf in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 76104c142fb25215bdfaabc91607ffbf in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 76104c142fb25215bdfaabc91607ffbf in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Thu, 22 Jun 2023 15:26:02 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '30027', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': '76104c142fb25215bdfaabc91607ffbf', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7db5812459f43e38-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: Bad gateway. {\"error\":{\"code\":502,\"message\":\"Bad gateway.\",\"param\":null,\"type\":\"cf_bad_gateway\"}} 502 {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}} {'Date': 'Thu, 22 Jun 2023 16:15:21 GMT', 'Content-Type': 'application/json', 'Content-Length': '84', 'Connection': 'keep-alive', 'X-Frame-Options': 'SAMEORIGIN', 'Referrer-Policy': 'same-origin', 'Cache-Control': 'private, max-age=0, no-store, no-cache, must-revalidate, post-check=0, pre-check=0', 'Expires': 'Thu, 01 Jan 1970 00:00:01 GMT', 'Server': 'cloudflare', 'CF-RAY': '7db5ca114cb187c3-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: The server had an error while processing your request. Sorry about that!.\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised APIError: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b61a6cac6f92f2f0f6fd8bf345814057 in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b61a6cac6f92f2f0f6fd8bf345814057 in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID b61a6cac6f92f2f0f6fd8bf345814057 in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Thu, 22 Jun 2023 19:00:33 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'talosix-2', 'openai-processing-ms': '32754', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-reset-requests': '20ms', 'x-request-id': 'b61a6cac6f92f2f0f6fd8bf345814057', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7db6bb4f3cb9496b-SIN', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    }
   ],
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "source": [
    "df[\"embeddings\"] = df[\"concat\"].copy().astype(object)\n",
    "# df[\"embeddings\"] = df[\"concat\"].progress_apply(\n",
    "#     lambda row: _generate_embedding(text=row, model=model, amount=2)\n",
    "# )\n",
    "\n",
    "if not os.path.exists(\"npy\"):\n",
    "    os.makedirs(\"npy\")\n",
    "\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    filename = f\"npy/{index}.npy\"\n",
    "    embedding = _generate_embedding(text=row[\"concat\"], model=model, amount=3)\n",
    "    row[\"embeddings\"] = embedding\n",
    "    # Cache the embeddings for future use\n",
    "    np.save(filename, embedding)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7bb3f77b574ad7933a06c3fb8dfe9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "source": [
    "df[\"embeddings\"] = df[\"embeddings\"].astype(object)\n",
    "for index, row in tqdm(df.iterrows()):\n",
    "    filename = f\"npy/{index}.npy\"\n",
    "    embedding = np.load(filename)\n",
    "    df[\"embeddings\"].loc[index] = embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"concat\"], axis=1)\n",
<<<<<<< HEAD
    "df.to_csv(\"csv/ctgov_studies_20230720_openai_embedding.csv\")\n"
=======
    "df.to_csv(\"ctgov_studies_20230621_openai_embedding.csv\")\n"
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "source": [
    "len(df[\"embeddings\"][0])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.009765988955702291,\n",
       " 0.0010155662695186536,\n",
       " 0.02044236619934322,\n",
       " -0.020456159086402918,\n",
       " -0.0004319173955913906]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "source": [
    "df[\"embeddings\"][0][:5]\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
=======
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00976599,  0.00101557,  0.02044237, ..., -0.02474602,\n",
       "       -0.01968371, -0.02139414])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> b0caa09c7a8417e5152f4f56be19ca1bc72b363b
   "source": [
    "arr = np.load(\"npy/NCT00000143.npy\")\n",
    "arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
