{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 437713 entries, NCT02421263 to NCT02467868\n",
      "Data columns (total 6 columns):\n",
      " #   Column                   Non-Null Count   Dtype \n",
      "---  ------                   --------------   ----- \n",
      " 0   brief_title              437713 non-null  object\n",
      " 1   study_type               436883 non-null  object\n",
      " 2   source                   437713 non-null  object\n",
      " 3   start_date               432681 non-null  object\n",
      " 4   verification_date        436883 non-null  object\n",
      " 5   primary_completion_date  415903 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 23.4+ MB\n"
     ]
    }
   ],
   "source": [
    "dataname = \"ctgov_437713_20230321\"\n",
    "filename = \"ctgov_437713_20230321.csv\"\n",
    "df = pd.read_csv(filename, index_col=\"nct_id\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_embedding(\n",
    "        text=None, \n",
    "        model=None,\n",
    "        modelname=None,\n",
    "        tokenizer=None, \n",
    "        size=256\n",
    "    ):\n",
    "    # print(modelname)\n",
    "    # Split the text into smaller chunks to fit the BERT model_name's input size\n",
    "    chunks = [text[i:i+size] for i in range(0, len(text), size)] # type: ignore\n",
    "    # Generate BERT embeddings for each chunk and concatenate them\n",
    "    embeddings = []\n",
    "    for chunk in chunks:\n",
    "        if \"openai\" in modelname: # type: ignore\n",
    "            chunk_embedding = openai.Embedding.create(\n",
    "                input=[chunk],\n",
    "                model=\"text-embedding-ada-002\"\n",
    "            )['data'][0]['embedding']  # type: ignore\n",
    "        else:\n",
    "            # Tokenize the text\n",
    "            tokens = tokenizer.encode(chunk, add_special_tokens=True)\n",
    "            device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "            tokens = torch.tensor([tokens]).to(device)\n",
    "\n",
    "            # Generate the BERT/GPT embeddings\n",
    "            chunk_outputs = model(tokens)\n",
    "            # Extract the tensor containing the embeddings\n",
    "            chunk_embeddings = chunk_outputs.last_hidden_state\n",
    "            # Average the embeddings over the sequence length to get a single vector for the chunk\n",
    "            chunk_embedding = torch.mean(chunk_embeddings, dim=1).tolist()[0]\n",
    "        embeddings.append(chunk_embedding)\n",
    "    row_embedding = np.array([sum(x) for x in zip(*embeddings)])\n",
    "    return row_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dir = os.path.join(os.path.curdir, 'cache')\n",
    "size = 256\n",
    "modelnames = [\n",
    "    # 'openai/text-embedding-ada-002',\n",
    "    'emilyalsentzer/Bio_ClinicalBERT', \n",
    "    'microsoft/biogpt'\n",
    "]\n",
    "column = 'brief_title'\n",
    "from_scratch = False\n",
    "if from_scratch:\n",
    "    for modelname in modelnames:\n",
    "        print(modelname)\n",
    "        if 'openai' in modelname:  # type: ignore\n",
    "            tokenizer = None\n",
    "            model = 'openai'\n",
    "\n",
    "            # # First, check the number to trials in temp folder\n",
    "            # np_files = glob.glob(os.path.join('temp', '*.npy'))\n",
    "            # print(f'{len(np_files)} out of {len(df)}')\n",
    "            # st_index = 0\n",
    "            # if len(np_files)>=2:\n",
    "            #     st_index = len(np_files)-2\n",
    "\n",
    "            # for index, row in tqdm(df[column][st_index:].iteritems()):\n",
    "            #     embedding = _generate_embedding(row,\n",
    "            #                                     tokenizer=tokenizer,\n",
    "            #                                     modelname=modelname,\n",
    "            #                                     model=model,\n",
    "            #                                     size=size)\n",
    "            #     np.save(f'temp/{index}.npy', embedding) # type: ignore\n",
    "            # if len(np_files) == len(df):\n",
    "            #     embeddings = []\n",
    "            #     for index, row in df[column].iteritems():\n",
    "            #         embedding = np.load(f'temp/{index}.npy')\n",
    "            #         print(f'temp/{index}.npy', (embedding.shape))\n",
    "            #         # df.loc[index, 'embedding'] = embedding\n",
    "            #         embeddings.append(np.array2string(embedding, separator=\",\", threshold=np.inf)) # type: ignore\n",
    "            #     df[[modelname]] = embeddings\n",
    "\n",
    "        else:\n",
    "            tokenizer = AutoTokenizer.from_pretrained(modelname, cache_dir=cache_dir)\n",
    "            model = AutoModel.from_pretrained(modelname, cache_dir=cache_dir)\n",
    "\n",
    "            device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "            model.to(device)\n",
    "\n",
    "            df[modelname] = df[column].progress_apply(\n",
    "                lambda row: _generate_embedding(\n",
    "                    row,\n",
    "                    tokenizer=tokenizer,\n",
    "                    modelname=modelname,\n",
    "                    model=model,\n",
    "                    size=size\n",
    "                ), # type: ignore\n",
    "            )\n",
    "\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "else:\n",
    "    dataset = Dataset.load_from_disk(dataname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['brief_title', 'study_type', 'source', 'start_date', 'verification_date', 'primary_completion_date', 'emilyalsentzer/Bio_ClinicalBERT', 'microsoft/biogpt', 'nct_id'],\n",
      "    num_rows: 437713\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetInfo(description='', citation='', homepage='', license='', features={'brief_title': Value(dtype='string', id=None), 'study_type': Value(dtype='string', id=None), 'source': Value(dtype='string', id=None), 'start_date': Value(dtype='string', id=None), 'verification_date': Value(dtype='string', id=None), 'primary_completion_date': Value(dtype='string', id=None), 'emilyalsentzer/Bio_ClinicalBERT': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'microsoft/biogpt': Sequence(feature=Value(dtype='float64', id=None), length=-1, id=None), 'nct_id': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name=None, config_name=None, version=None, splits=None, download_checksums=None, download_size=None, post_processing_size=None, dataset_size=None, size_in_bytes=None)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emilyalsentzer/Bio_ClinicalBERT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3940350090414e1ca84a20414a5808a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/biogpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5839dd85791497b85aae64f32a11952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/438 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for modelname in modelnames:\n",
    "    print(modelname)\n",
    "    # dataset.add_faiss_index(column='embeddings')\n",
    "    dataset.add_faiss_index(column=modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              brief_title  \\\n",
      "0       The Effects of Psilocybin-Facilitated Experien...   \n",
      "1       Study to Explore the Safety, Tolerability and ...   \n",
      "2       Phase II Study of DC Versus 5-FU/CF as Chemoth...   \n",
      "3       Small Intestinal Bacterial Overgrowth: A Prosp...   \n",
      "4       Prevalence and Clinical Severity of Cutaneous ...   \n",
      "...                                                   ...   \n",
      "437708  Hyper-synchronicity in Hypertrophic Cardiomyop...   \n",
      "437709  Anti-OX40 Antibody (MEDI6469) in Patients With...   \n",
      "437710  Pharmacokinetic / Pharmacodynamic Study Compar...   \n",
      "437711  Study of Efficacy and Safety of Myl1401O + Tax...   \n",
      "437712  Efficacy and Safety Study With MYL-1401H and N...   \n",
      "\n",
      "                              study_type                         source  \\\n",
      "0                         Interventional             NYU Langone Health   \n",
      "1                         Interventional             Incyte Corporation   \n",
      "2                         Interventional               Wuhan University   \n",
      "3       Observational [Patient Registry]             Indiana University   \n",
      "4                          Observational     University of Pennsylvania   \n",
      "...                                  ...                            ...   \n",
      "437708                    Interventional  University Hospital, Bordeaux   \n",
      "437709                    Interventional   Providence Health & Services   \n",
      "437710                    Interventional                   Viatris Inc.   \n",
      "437711                    Interventional                   Viatris Inc.   \n",
      "437712                    Interventional                   Viatris Inc.   \n",
      "\n",
      "        start_date verification_date primary_completion_date  \\\n",
      "0       2015-04-30        2022-02-28              2020-06-05   \n",
      "1       2014-07-17        2022-02-28              2018-11-26   \n",
      "2       2013-05-31        2022-01-31              2023-06-01   \n",
      "3       2013-01-31        2022-02-28              2024-12-31   \n",
      "4       2006-12-31        2022-01-31              2025-01-02   \n",
      "...            ...               ...                     ...   \n",
      "437708  2015-06-22        2022-02-28              2019-01-19   \n",
      "437709  2016-03-14        2022-01-31              2018-10-31   \n",
      "437710  2014-09-30        2022-02-28              2015-06-30   \n",
      "437711  2012-07-31        2022-02-28              2016-03-31   \n",
      "437712  2015-03-31        2022-02-28              2015-09-30   \n",
      "\n",
      "                          emilyalsentzer/Bio_ClinicalBERT  \\\n",
      "0       [0.08038566261529922, -0.10499667376279831, -0...   \n",
      "1       [0.4052324593067169, 0.059391096234321594, -0....   \n",
      "2       [0.20893026888370514, 0.1370815485715866, -0.1...   \n",
      "3       [0.2793894112110138, 0.20599709451198578, -0.4...   \n",
      "4       [0.3323464095592499, -0.21661478281021118, -0....   \n",
      "...                                                   ...   \n",
      "437708  [0.03948963060975075, 0.01891828514635563, 0.0...   \n",
      "437709  [0.2269926816225052, -0.024331187829375267, -0...   \n",
      "437710  [0.09061188995838165, -0.045515432953834534, -...   \n",
      "437711  [0.1484503448009491, 0.1325123906135559, -0.16...   \n",
      "437712  [0.14126604795455933, -0.09416748583316803, -0...   \n",
      "\n",
      "                                         microsoft/biogpt       nct_id  \n",
      "0       [-0.10043824464082718, 0.8783055543899536, 0.1...  NCT02421263  \n",
      "1       [-0.7091686129570007, 0.6373722553253174, -1.2...  NCT02178722  \n",
      "2       [0.8390743732452393, 1.6733291149139404, -0.62...  NCT01889303  \n",
      "3       [-0.856123149394989, 1.1302772760391235, -1.10...  NCT01822470  \n",
      "4       [1.2600584030151367, 1.3250700235366821, -1.17...  NCT01510067  \n",
      "...                                                   ...          ...  \n",
      "437708  [-0.03497118130326271, 1.5936394929885864, -1....  NCT02559726  \n",
      "437709  [-0.43611714243888855, 1.1874001026153564, -0....  NCT02559024  \n",
      "437710  [-1.738901138305664, 0.272760272026062, 0.2925...  NCT02479646  \n",
      "437711  [-0.7101901769638062, 0.6237466931343079, -0.1...  NCT02472964  \n",
      "437712  [-1.4731357097625732, 0.6123418211936951, 0.66...  NCT02467868  \n",
      "\n",
      "[437713 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df = dataset.to_pandas()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 0.0 NCT02421263 The Effects of Psilocybin-Facilitated Experience on the Psychology and Effectiveness of Religious Professionals\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 5.5929375 NCT02243813 Effects of Psilocybin-facilitated Experience on the Psychology and Effectiveness of Professional Leaders in Religion\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 11.584749 NCT05652803 Bibliotherapy-based Psychoeducation Program the Effect of Elderly Individuals on Depression and Hopelessness Levels\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 12.550905 NCT03389568 The Effects of Singing-based Music Therapy Program on the Level of Psychoemotional Benefits in Caregivers of ICU Patients\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 12.657162 NCT05508048 The Effects of Logotherapy Based Psychosocial Support Program on Nursing Students on the Meaning of Life and Life Satisfaction\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 12.846097 NCT03232541 The Effects of Acupuncture and the TherapistÂ´s Communication on Chemotherapy Induced Nausea and Vomiting\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 13.568081 NCT05263323 The Effect of the Training on Adaptation to Treatment Provided to Hemodialysis Patients According to the Neuman Systems Theory on Self-Esteem and Perceived Social Support\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 13.59007 NCT04690881 The Effect of Psychodrama for Treating Fear of Childbirth\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 13.66464 NCT04822051 The Effect of Psychoeducation Based on Uncertainty In Illness Theory On Schizophrenia Caregivers\n",
      "emilyalsentzer/Bio_ClinicalBERT NCT02421263 13.843621 NCT04138368 The Effect of Early Dyadic Psychotherapy for Mothers Suffering From PPD on Oxytocin Level and on Childrens' Emotional Development\n",
      "microsoft/biogpt NCT02421263 0.0 NCT02421263 The Effects of Psilocybin-Facilitated Experience on the Psychology and Effectiveness of Religious Professionals\n",
      "microsoft/biogpt NCT02421263 46.79433 NCT02243813 Effects of Psilocybin-facilitated Experience on the Psychology and Effectiveness of Professional Leaders in Religion\n",
      "microsoft/biogpt NCT02421263 210.49875 NCT01988311 Pilot Study: Effects of Psilocybin on Behavior, Psychology and Brain Function in Long-term Meditators\n",
      "microsoft/biogpt NCT02421263 222.22617 NCT04522804 Study of Psilocybin Enhanced Group Psychotherapy in Patients With Cancer\n",
      "microsoft/biogpt NCT02421263 234.24255 NCT02145091 Effects of Psilocybin on Behavior, Psychology and Brain Function in Long-term Meditators\n",
      "microsoft/biogpt NCT02421263 240.65155 NCT04630964 The Effect of Psilocybin on MDD Symptom Severity and Synaptic Density\n",
      "microsoft/biogpt NCT02421263 247.92268 NCT05381974 The Effects of Psilocybin on Self-Focus and Self-Related Processing in Treatment Resistant MDD\n",
      "microsoft/biogpt NCT02421263 249.98859 NCT05265546 Investigating the Mechanisms of the Effects of Psilocybin on Visual Perception and Visual Representations in the Brain\n",
      "microsoft/biogpt NCT02421263 261.8935 NCT04950608 Pilot Study of Psilocybin-Assisted Therapy for Demoralization in Patients Receiving Hospice Care\n",
      "microsoft/biogpt NCT02421263 262.37527 NCT05478278 An Evaluation of Psilocybin's Effect on Cardiac Repolarization\n"
     ]
    }
   ],
   "source": [
    "nct_id = \"NCT02421263\" \n",
    "for modelname in modelnames:\n",
    "    nct_id_embedding = np.array(df[df[\"nct_id\"] == nct_id][modelname][0])\n",
    "    # print(nct_id_embedding)\n",
    "    scores, retrieved_examples = dataset.get_nearest_examples(\n",
    "        modelname, nct_id_embedding, k=10)\n",
    "    # print(scores, retrieved_examples[column])\n",
    "    for score, index, title in zip(scores, retrieved_examples[\"nct_id\"], retrieved_examples[\"brief_title\"]):\n",
    "        print(modelname, nct_id, score, index, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# token = \"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\"\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "\n",
    "# url = \"https://huggingface.co/api/datasets/tmquan/ctgov-studies-embeddings/commit/main\"\n",
    "# params = {\"create_pr\": 1}\n",
    "\n",
    "# response = requests.post(url, params=params)\n",
    "\n",
    "# if response.status_code == 200:\n",
    "#     print(\"Pull Request created successfully.\")\n",
    "# else:\n",
    "#     print(\"Error:\", response.status_code, response.reason)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.push_to_hub(\"ctgov-studies-embeddings\", private=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if from_scratch:\n",
    "    dataset.save_to_disk(dataname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ctgov-studies-embeddings.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"tmquan/ctgov-studies-embeddings\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textkit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
